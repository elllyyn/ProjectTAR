{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He loves to stroll at the park with his bed</td>\n",
       "      <td>He loves to stroll at the park with his dog.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The inverter was able to power the continent.</td>\n",
       "      <td>The inverter was able to power the house</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The chef put extra lemons on the pizza.</td>\n",
       "      <td>The chef put extra mushrooms on the pizza.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sugar is used to make coffee sour</td>\n",
       "      <td>sugar is used to make coffee sweet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are beautiful flowers here and there in ...</td>\n",
       "      <td>There are beautiful planes here and there in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0   \n",
       "0        He loves to stroll at the park with his bed  \\\n",
       "1      The inverter was able to power the continent.   \n",
       "2            The chef put extra lemons on the pizza.   \n",
       "3                  sugar is used to make coffee sour   \n",
       "4  There are beautiful flowers here and there in ...   \n",
       "\n",
       "                                               sent1  answer  \n",
       "0       He loves to stroll at the park with his dog.       0  \n",
       "1           The inverter was able to power the house       0  \n",
       "2         The chef put extra mushrooms on the pizza.       0  \n",
       "3                 sugar is used to make coffee sweet       0  \n",
       "4  There are beautiful planes here and there in t...       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load CSV files.\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#CSV task A \n",
    "df_train_data_A = pd.read_csv(\"data/Training_Data/subtaskA_data_all.csv\")\n",
    "df_train_answers_A = pd.read_csv(\"data/Training_Data/subtaskA_answers_all.csv\")\n",
    "\n",
    "df_train_A = pd.merge(df_train_data_A,df_train_answers_A,on='id', how='left').drop(['id'], axis=1)\n",
    "df_train_A.head()\n",
    "\n",
    "df_test_data_A = pd.read_csv(\"data/Test_Data/subtaskA_test_data.csv\")\n",
    "df_test_answers_A = pd.read_csv(\"data/Test_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "df_test_A = pd.merge(df_test_data_A,df_test_answers_A,on='id', how='left').drop(['id'], axis=1)\n",
    "df_test_A.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from podium import Vocab, Field, LabelField\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.vectorizers import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30053881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\podium\\vocab.py:514: UserWarning: Vocabulary is finalized already. This should be used only if multiple fields use same vocabulary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_vocab_size = 10_000\n",
    "vocab = Vocab(max_size=max_vocab_size, min_freq=2)\n",
    "\n",
    "def lowercase(raw):\n",
    "    return raw.lower()\n",
    "\n",
    "S0 = Field(name='sent0', numericalizer=vocab)\n",
    "S1 = Field(name='sent1', numericalizer=vocab)\n",
    "LABEL = LabelField(name='answer') # Label field\n",
    "\n",
    "\n",
    "fields = [\n",
    "    S0,\n",
    "    S1,\n",
    "    LABEL,\n",
    "]\n",
    "\n",
    "train = TabularDataset.from_pandas(df_train_A, fields)\n",
    "test = TabularDataset.from_pandas(df_test_A, fields)\n",
    "train.finalize_fields()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 862M/862M [03:44<00:00, 3.84MB/s]\n"
     ]
    }
   ],
   "source": [
    "glove = GloVe()\n",
    "# Load only the vectors of vocab words.\n",
    "embeddings = glove.load_vocab(vocab)\n",
    "\n",
    "# Generate padded batch.\n",
    "train_batch = train.batch(add_padding=True)\n",
    "test_batch = test.batch(add_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.array([np.dot(a[i, :], b[i, :])/(np.linalg.norm(a[i, :])*np.linalg.norm(b[i, :])) for i in range(a.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(sims, n=10):\n",
    "    index = np.argsort(sims)[-n:]\n",
    "    return np.sort(index)\n",
    "def meanVect(vector):\n",
    "    return vector.mean(axis=1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d043cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence0_train, sentence1_train = embeddings[train_batch['sent0']], embeddings[train_batch['sent1']]\n",
    "sentence0_test, sentence1_test = embeddings[test_batch['sent0']], embeddings[test_batch['sent1']]\n",
    "\n",
    "label_train = train_batch['answer']\n",
    "label_test = test_batch['answer']\n",
    "\n",
    "sentence0_train_mean, sentence1_train_mean = meanVect(sentence0_train), meanVect(sentence1_train)\n",
    "sentence0_test_mean, sentence1_test_mean = meanVect(sentence0_test), meanVect(sentence1_test)\n",
    "\n",
    "X_train_mul, X_test_mul = np.multiply(sentence0_train_mean, sentence1_train_mean), np.multiply(sentence0_test_mean, sentence0_test_mean)\n",
    "X_train_cat, X_test_cat = np.concatenate((sentence0_train_mean, sentence1_train_mean), axis=1), np.concatenate((sentence0_test_mean, sentence1_test_mean), axis=1)\n",
    "y_train, y_test = label_train.reshape(label_train.shape[0],), label_test.reshape(label_test.shape[0],)\n",
    "                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e67a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "\n",
    "#return a logisitc regression model fi\n",
    "def train_model(X_train, y_train):\n",
    "    lr_kwargs={\"max_iter\": 1000, \"solver\": \"lbfgs\"}\n",
    "    return LR(**lr_kwargs).fit(X_train, y_train)\n",
    "\n",
    "def test_performance(model, x_test, y_test):\n",
    "    type(model)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae8746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplied Representation: \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiplied Representation: \")\n",
    "lr = train_model(X_train_mul, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72159d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.54      0.50       492\n",
      "           1       0.48      0.41      0.44       508\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.47      0.48      0.47      1000\n",
      "weighted avg       0.47      0.47      0.47      1000\n",
      "\n",
      "f1 = 0.439\n"
     ]
    }
   ],
   "source": [
    "f1 = test_performance(lr, X_test_mul, y_test)\n",
    "print(f\"f1 = {f1:.3f}\") #found f1=0.439\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Representation: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.55       492\n",
      "           1       0.57      0.60      0.59       508\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.57      0.57      0.57      1000\n",
      "weighted avg       0.57      0.57      0.57      1000\n",
      "\n",
      "f1 = 0.586\n"
     ]
    }
   ],
   "source": [
    "print(\"Concatenated Representation: \")\n",
    "lr = train_model(X_train_cat, y_train)\n",
    "f1 = test_performance(lr, X_test_cat, y_test)\n",
    "print(f\"f1 = {f1:.3f}\") #found f1=0.586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
