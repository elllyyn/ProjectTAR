{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99912d41",
   "metadata": {},
   "source": [
    "Source code of every test for the task A with a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files.\n",
    "#CSV task A \n",
    "def getData():\n",
    "    df_train_data = pd.read_csv(\"data/Training_Data/subtaskA_data_all.csv\")\n",
    "    df_train_answers = pd.read_csv(\"data/Training_Data/subtaskA_answers_all.csv\")\n",
    "\n",
    "    df_train = pd.merge(df_train_data,df_train_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    df_dev_data = pd.read_csv(\"data/Dev_Data/subtaskA_dev_data.csv\")\n",
    "    df_dev_answers = pd.read_csv(\"data/Dev_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_dev = pd.merge(df_dev_data,df_dev_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "\n",
    "    df_test_data = pd.read_csv(\"data/Test_Data/subtaskA_test_data.csv\")\n",
    "    df_test_answers = pd.read_csv(\"data/Test_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_test= pd.merge(df_test_data,df_test_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    return df_train, df_dev, df_test\n",
    "\n",
    "df_train_A, df_dev_A, df_test_A = getData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980b04d",
   "metadata": {},
   "source": [
    "Methods to pre-process the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed3d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        str+=\" \"+token.lemma_\n",
    "    return str \n",
    "\n",
    "\n",
    "def stemmatizer(text) :\n",
    "    \"\"\"\n",
    "    Receive a string in input and stem it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        str += \"\"+stemmer.stem(token.text)\n",
    "    return str\n",
    "\n",
    "def removeStopWords(text):\n",
    "    \"\"\"\n",
    "    Receives a string and remove stop words from it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if(not token.is_stop):\n",
    "            str+=\" \"+token.text\n",
    "    return str \n",
    "\n",
    "def ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Receives a text and generates n-grams.\n",
    "    \"\"\"\n",
    "    sequence=[]\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        sequence.append(token.text)\n",
    "    return list(tuple([sequence[i] for i in range(i, i+n)]) for i in range(len(sequence)-n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474e1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "780ed56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['chemical_element', 'noble_gas'], ['letter']),\n",
       " (['helping'],\n",
       "  ['intemperance'],\n",
       "  ['food', 'liquid'],\n",
       "  ['body_of_water'],\n",
       "  ['consumption'],\n",
       "  ['consume'],\n",
       "  ['consume'],\n",
       "  ['honor'],\n",
       "  ['steep'],\n",
       "  ['use']),\n",
       " (['edible_fruit', 'pome'], ['apple_tree']),\n",
       " ()]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def synsets(text, function):\n",
    "    \"\"\"\n",
    "    Receives a text and return a list of synsets\n",
    "    \"\"\"\n",
    "    text = text.replace(\".\",\" .\")\n",
    "    sequence=text.split()\n",
    "    L = []\n",
    "    for seq in sequence:\n",
    "        L.append(tuple(function(s) for s in wn.synsets(seq)))\n",
    "    return L\n",
    "\n",
    "def getLemmasNames(synset):\n",
    "    return [str(lemma.name()) for lemma in synset.lemmas()]\n",
    "\n",
    "def getHypernyms(synset):\n",
    "    return [s.name().split(\".\")[0] for s in synset.hypernyms() ]\n",
    "\n",
    "\n",
    "    \n",
    "synsets(\"He drinks apple.\", getLemmasNames)\n",
    "synsets(\"He drinks apple.\", getHypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b149b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, function):\n",
    "    newdf = df[['sent0', 'sent1']]\n",
    "    newdf.loc[:,\"sent0\"] = df.sent0.apply(function)\n",
    "    newdf.loc[:,\"sent1\"] = df.sent1.apply(function)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c848f3",
   "metadata": {},
   "source": [
    "Process of data frame, create subsample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3339fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampleData():\n",
    "    # subsample data \n",
    "    train = df_train_A.sample(n=1000, random_state=42)\n",
    "    X_train = train[['sent0', 'sent1']]\n",
    "    y_train = train['answer']\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "# use the dev set for testing\n",
    "X_test = df_dev_A[['sent0', 'sent1']]\n",
    "y_test = df_dev_A['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03628df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "def test_performance(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18219886",
   "metadata": {},
   "source": [
    "Importation of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(max_seq_length=64, train_batch_size=16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "#model.num_mlp_layers = 3\n",
    "model.max_seq_length = 64\n",
    "model.epochs = 3\n",
    "#model.learning_rate = 4e-5\n",
    "                             \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train = subsampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2010901",
   "metadata": {},
   "source": [
    "Fit with different preprocess type                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29370070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>a duck walks on three legs</td>\n",
       "      <td>a duck walks on two legs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Jack's mom praised him because he broke the plate</td>\n",
       "      <td>Jack's mom condemned him because he broke the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>People use electricity to buy things</td>\n",
       "      <td>People use money to buy things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>The speaker is damaged, thus I can't hear anyt...</td>\n",
       "      <td>The display is damaged, thus I can't hear anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Santa Claus is the legend of the East</td>\n",
       "      <td>Santa Claus is the legend of the West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sent0   \n",
       "6252                         a duck walks on three legs  \\\n",
       "4684  Jack's mom praised him because he broke the plate   \n",
       "1731               People use electricity to buy things   \n",
       "4742  The speaker is damaged, thus I can't hear anyt...   \n",
       "4521              Santa Claus is the legend of the East   \n",
       "\n",
       "                                                  sent1  \n",
       "6252                           a duck walks on two legs  \n",
       "4684  Jack's mom condemned him because he broke the ...  \n",
       "1731                     People use money to buy things  \n",
       "4742  The display is damaged, thus I can't hear anyt...  \n",
       "4521              Santa Claus is the legend of the West  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7abe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_classic = model.fit(X_train_sample, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691fbcf",
   "metadata": {},
   "source": [
    "With lemmas names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0783982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f66f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>[([angstrom, angstrom_unit, A], [vitamin_A, an...</td>\n",
       "      <td>[([angstrom, angstrom_unit, A], [vitamin_A, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>[(), ([ma, mama, mamma, mom, momma, mommy, mam...</td>\n",
       "      <td>[(), ([ma, mama, mamma, mom, momma, mommy, mam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>[([people], [citizenry, people], [people], [mu...</td>\n",
       "      <td>[([people], [citizenry, people], [people], [mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>[(), ([speaker, talker, utterer, verbalizer, v...</td>\n",
       "      <td>[(), ([display, show], [display, exhibit, show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>[([Santa_Claus, Santa, Kriss_Kringle, Father_C...</td>\n",
       "      <td>[([Santa_Claus, Santa, Kriss_Kringle, Father_C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sent0   \n",
       "6252  [([angstrom, angstrom_unit, A], [vitamin_A, an...  \\\n",
       "4684  [(), ([ma, mama, mamma, mom, momma, mommy, mam...   \n",
       "1731  [([people], [citizenry, people], [people], [mu...   \n",
       "4742  [(), ([speaker, talker, utterer, verbalizer, v...   \n",
       "4521  [([Santa_Claus, Santa, Kriss_Kringle, Father_C...   \n",
       "\n",
       "                                                  sent1  \n",
       "6252  [([angstrom, angstrom_unit, A], [vitamin_A, an...  \n",
       "4684  [(), ([ma, mama, mamma, mom, momma, mommy, mam...  \n",
       "1731  [([people], [citizenry, people], [people], [mu...  \n",
       "4742  [(), ([display, show], [display, exhibit, show...  \n",
       "4521  [([Santa_Claus, Santa, Kriss_Kringle, Father_C...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fn = partial(synsets, function=getLemmasNames)\n",
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_lemma = pre_process(X_test,pipe_fn)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "226fa98e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [08:09<00:00,  8.59s/it, loss=0.737]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:42<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7369, Val loss: 0.7339, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [08:24<00:00,  8.85s/it, loss=0.701]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:41<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.7011, Val loss: 0.7060, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:51<00:00,  8.27s/it, loss=0.699]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6988, Val loss: 0.6928, Val accy: 55.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_lemma = model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7d899f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:17<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.04      0.07       518\n",
      "           1       0.48      0.95      0.64       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.47      0.50      0.35       997\n",
      "weighted avg       0.47      0.48      0.34       997\n",
      "\n",
      "f1 = 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:04<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       518\n",
      "           1       0.48      1.00      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.49      0.50      0.33       997\n",
      "weighted avg       0.49      0.48      0.31       997\n",
      "\n",
      "f1 = 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1 = test_performance(model_lemma, X_test, y_test)\n",
    "print(f\"f1 = {f1:.3f}\")\n",
    "f1 = test_performance(model_lemma, X_test_lemma, y_test)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfcfd4",
   "metadata": {},
   "source": [
    "With hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c07bdc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:30<00:00,  7.91s/it, loss=0.735]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:37<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7352, Val loss: 0.7272, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|████████████████████████████████████████████████████████████| 57/57 [08:55<00:00,  9.39s/it, loss=0.7]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:45<00:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6997, Val loss: 0.7100, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [09:04<00:00,  9.55s/it, loss=0.694]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:45<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6942, Val loss: 0.6929, Val accy: 55.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:03<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.01      0.03       518\n",
      "           1       0.48      0.99      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.51      0.50      0.34       997\n",
      "weighted avg       0.51      0.48      0.32       997\n",
      "\n",
      "f1 = 0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:03<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       518\n",
      "           1       0.48      1.00      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.24      0.50      0.32       997\n",
      "weighted avg       0.23      0.48      0.31       997\n",
      "\n",
      "f1 = 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe_fn = partial(synsets, function=getHypernyms)\n",
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_hypernyms = pre_process(X_test,pipe_fn)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "model_hypernyms = model.fit(X_train, y_train)\n",
    "\n",
    "f1 = test_performance(model_hypernyms, X_test, y_test)\n",
    "print(f\"f1 = {f1:.3f}\")\n",
    "f1 = test_performance(model_hypernyms, X_test_hypernyms, y_test)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74815d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aeb2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c368f47",
   "metadata": {},
   "source": [
    "To save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "savefile = 'BERT_TaskA.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7278d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
