{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824f0db5",
   "metadata": {},
   "source": [
    "Source code of every test for the task A with a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He poured orange juice on his cereal.</td>\n",
       "      <td>Orange juice is usually bright orange.</td>\n",
       "      <td>Orange juice doesn't taste good on cereal.</td>\n",
       "      <td>Orange juice is sticky if you spill it on the ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He drinks apple.</td>\n",
       "      <td>Apple juice are very tasty and milk too</td>\n",
       "      <td>Apple can not be drunk</td>\n",
       "      <td>Apple cannot eat a human</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff ran 100,000 miles today</td>\n",
       "      <td>100,000 miles is way to long for one person to...</td>\n",
       "      <td>Jeff is a four letter name and 100,000 has six...</td>\n",
       "      <td>100,000 miles is longer than 100,000 km.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I sting a mosquito</td>\n",
       "      <td>A human is a mammal</td>\n",
       "      <td>A human is omnivorous</td>\n",
       "      <td>A human has not stings</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A giraffe is a person.</td>\n",
       "      <td>Giraffes can drink water from a lake.</td>\n",
       "      <td>A giraffe is not a human being.</td>\n",
       "      <td>.Giraffes usually eat leaves.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               FalseSent   \n",
       "0  He poured orange juice on his cereal.  \\\n",
       "1                       He drinks apple.   \n",
       "2           Jeff ran 100,000 miles today   \n",
       "3                     I sting a mosquito   \n",
       "4                 A giraffe is a person.   \n",
       "\n",
       "                                             OptionA   \n",
       "0             Orange juice is usually bright orange.  \\\n",
       "1            Apple juice are very tasty and milk too   \n",
       "2  100,000 miles is way to long for one person to...   \n",
       "3                                A human is a mammal   \n",
       "4              Giraffes can drink water from a lake.   \n",
       "\n",
       "                                             OptionB   \n",
       "0         Orange juice doesn't taste good on cereal.  \\\n",
       "1                             Apple can not be drunk   \n",
       "2  Jeff is a four letter name and 100,000 has six...   \n",
       "3                              A human is omnivorous   \n",
       "4                    A giraffe is not a human being.   \n",
       "\n",
       "                                             OptionC answer  \n",
       "0  Orange juice is sticky if you spill it on the ...      B  \n",
       "1                           Apple cannot eat a human      B  \n",
       "2           100,000 miles is longer than 100,000 km.      A  \n",
       "3                             A human has not stings      C  \n",
       "4                      .Giraffes usually eat leaves.      B  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files.\n",
    "# CSV task B\n",
    "def getData():\n",
    "    df_train_data = pd.read_csv(\"data/Training_Data/subtaskB_data_all.csv\")\n",
    "    df_train_answers = pd.read_csv(\"data/Training_Data/subtaskB_answers_all.csv\")\n",
    "\n",
    "    df_train = pd.merge(df_train_data,df_train_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    df_dev_data = pd.read_csv(\"data/Dev_Data/subtaskB_dev_data.csv\")\n",
    "    df_dev_answers = pd.read_csv(\"data/Dev_Data/subtaskB_gold_answers.csv\")\n",
    "\n",
    "    df_dev = pd.merge(df_dev_data,df_dev_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "\n",
    "    df_test_data = pd.read_csv(\"data/Test_Data/subtaskB_test_data.csv\")\n",
    "    df_test_answers = pd.read_csv(\"data/Test_Data/subtaskB_gold_answers.csv\")\n",
    "\n",
    "    df_test= pd.merge(df_test_data,df_test_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    return df_train, df_dev, df_test\n",
    "\n",
    "df_train_B, df_dev_B, df_test_B = getData()\n",
    "\n",
    "df_train_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ad9dd",
   "metadata": {},
   "source": [
    "Methods to pre-process the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6060bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        str+=\" \"+token.lemma_\n",
    "    return str \n",
    "\n",
    "\n",
    "def stemmatizer(text) :\n",
    "    \"\"\"\n",
    "    Receive a string in input and stem it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        str += \"\"+stemmer.stem(token.text)\n",
    "    return str\n",
    "\n",
    "def removeStopWords(text):\n",
    "    \"\"\"\n",
    "    Receives a string and remove stop words from it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if(not token.is_stop):\n",
    "            str+=\" \"+token.text\n",
    "    return str \n",
    "\n",
    "def ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Receives a text of tokens and generates n-grams.\n",
    "    \"\"\"\n",
    "    sequence=[]\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        sequence.append(token.text)\n",
    "    return list(tuple([sequence[i] for i in range(i, i+n)]) for i in range(len(sequence)-n+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7333a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, function):\n",
    "    newdf = df[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "    newdf.loc[:,\"FalseSent\"] = df.FalseSent.apply(function)\n",
    "    newdf.loc[:,\"OptionA\"] = df.OptionA.apply(function)\n",
    "    newdf.loc[:,\"OptionB\"] = df.OptionB.apply(function)\n",
    "    newdf.loc[:,\"OptionC\"] = df.OptionC.apply(function)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9c408",
   "metadata": {},
   "source": [
    "Process of data frame, create subsample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23457d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampleData():\n",
    "    # subsample data \n",
    "    train = df_train_B.sample(n=1000, random_state=42)\n",
    "\n",
    "    X_train = train[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "    y_train = train['answer']\n",
    "\n",
    "    # use the dev set for testing  \n",
    "    return X_train, y_train\n",
    "\n",
    "X_test = df_dev_B[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "y_test = df_dev_B['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c97f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "def test_performance(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\"), f1_score(y_pred=y_pred, y_true=y_test, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cefbe3",
   "metadata": {},
   "source": [
    "Importation of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(max_seq_length=64, train_batch_size=16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "#model.num_mlp_layers = 3\n",
    "model.max_seq_length = 64\n",
    "model.epochs = 3\n",
    "#model.learning_rate = 4e-5\n",
    "                             \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train= subsampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf29aa4",
   "metadata": {},
   "source": [
    "Fit with different preprocess type                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ad8073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>a duck walks on three legs</td>\n",
       "      <td>the duck's legs are short</td>\n",
       "      <td>a duck has only two legs</td>\n",
       "      <td>a duck has two wings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Jack's mom praised him because he broke the plate</td>\n",
       "      <td>Breaking a plate is not a good thing, people w...</td>\n",
       "      <td>Plates are easy to break, people need to be ca...</td>\n",
       "      <td>Plates can be made of ceramic or plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>People use electricity to buy things</td>\n",
       "      <td>It is impossible to buy things with electricity</td>\n",
       "      <td>Electricity is essential to live</td>\n",
       "      <td>Many appliances in home works on electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>The display is damaged, thus I can't hear anyt...</td>\n",
       "      <td>Display can also be used to create sound with ...</td>\n",
       "      <td>Display cannot be used to aid people's hearing</td>\n",
       "      <td>Display is used to display things, people will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Santa Claus is the legend of the East</td>\n",
       "      <td>Christmas is very grand in the West</td>\n",
       "      <td>The origin of Christmas is not in the East</td>\n",
       "      <td>Western countries are very respectful of Santa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FalseSent   \n",
       "6252                         a duck walks on three legs  \\\n",
       "4684  Jack's mom praised him because he broke the plate   \n",
       "1731               People use electricity to buy things   \n",
       "4742  The display is damaged, thus I can't hear anyt...   \n",
       "4521              Santa Claus is the legend of the East   \n",
       "\n",
       "                                                OptionA   \n",
       "6252                          the duck's legs are short  \\\n",
       "4684  Breaking a plate is not a good thing, people w...   \n",
       "1731    It is impossible to buy things with electricity   \n",
       "4742  Display can also be used to create sound with ...   \n",
       "4521                Christmas is very grand in the West   \n",
       "\n",
       "                                                OptionB   \n",
       "6252                           a duck has only two legs  \\\n",
       "4684  Plates are easy to break, people need to be ca...   \n",
       "1731                   Electricity is essential to live   \n",
       "4742     Display cannot be used to aid people's hearing   \n",
       "4521         The origin of Christmas is not in the East   \n",
       "\n",
       "                                                OptionC  \n",
       "6252                               a duck has two wings  \n",
       "4684           Plates can be made of ceramic or plastic  \n",
       "1731       Many appliances in home works on electricity  \n",
       "4742  Display is used to display things, people will...  \n",
       "4521  Western countries are very respectful of Santa...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b7abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:00<?, ?it/s]C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [06:59<00:00,  7.37s/it, loss=1.07]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.0667, Val loss: 0.9957, Val accy: 53.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:02<00:00,  7.41s/it, loss=0.855]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.8551, Val loss: 0.9771, Val accy: 55.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [06:57<00:00,  7.33s/it, loss=0.592]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.5921, Val loss: 1.0101, Val accy: 56.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:37<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.65      0.66       344\n",
      "           B       0.38      0.28      0.32       327\n",
      "           C       0.43      0.56      0.48       326\n",
      "\n",
      "    accuracy                           0.50       997\n",
      "   macro avg       0.49      0.49      0.49       997\n",
      "weighted avg       0.49      0.50      0.49       997\n",
      "\n",
      "f1micro = 0.496 and f1macro = 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_classic = model.fit(X_train_sample, y_train)\n",
    "f1macro, f1micro = test_performance(model_classic, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bbd9af",
   "metadata": {},
   "source": [
    "With only lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bfb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_process(X_train_sample,lemmatizer)\n",
    "X_train.head()\n",
    "\n",
    "X_test_lemma = pre_process(X_test,lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2f0b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [06:46<00:00,  7.13s/it, loss=1.06]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.0588, Val loss: 0.9912, Val accy: 54.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:06<00:00,  7.48s/it, loss=0.841]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.8407, Val loss: 0.9203, Val accy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:17<00:00,  7.68s/it, loss=0.571]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.5711, Val loss: 0.9451, Val accy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:48<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.65      0.67      0.66       344\n",
      "           B       0.35      0.20      0.26       327\n",
      "           C       0.42      0.58      0.49       326\n",
      "\n",
      "    accuracy                           0.49       997\n",
      "   macro avg       0.47      0.48      0.47       997\n",
      "weighted avg       0.48      0.49      0.47       997\n",
      "\n",
      "f1micro = 0.487 and f1macro = 0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:46<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.66      0.67       344\n",
      "           B       0.38      0.30      0.33       327\n",
      "           C       0.43      0.53      0.47       326\n",
      "\n",
      "    accuracy                           0.50       997\n",
      "   macro avg       0.49      0.50      0.49       997\n",
      "weighted avg       0.50      0.50      0.49       997\n",
      "\n",
      "f1micro = 0.499 and f1macro = 0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_lemma = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_lemma, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_lemma, X_test_lemma, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302eeb0d",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2233121",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_process(X_train_sample,removeStopWords)\n",
    "X_train.head()\n",
    "X_test_stopWords = pre_process(X_test,removeStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b40e94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [06:36<00:00,  6.95s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1188, Val loss: 1.1037, Val accy: 33.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [07:05<00:00,  7.46s/it, loss=1.11]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.1075, Val loss: 1.1018, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|████████████████████████████████████████████████████████████| 57/57 [07:06<00:00,  7.47s/it, loss=1.1]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:34<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.0979, Val loss: 1.0933, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:36<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.35      1.00      0.51       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.00      0.00      0.00       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.12      0.33      0.17       997\n",
      "weighted avg       0.12      0.35      0.18       997\n",
      "\n",
      "f1micro = 0.345 and f1macro = 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:39<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.35      1.00      0.51       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.00      0.00      0.00       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.12      0.33      0.17       997\n",
      "weighted avg       0.12      0.35      0.18       997\n",
      "\n",
      "f1micro = 0.345 and f1macro = 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_stopWords = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_stopWords, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_stopWords, X_test_stopWords, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281a6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_process(X_train_sample,removeStopWords)\n",
    "X_train = pre_process(X_train,lemmatizer)\n",
    "\n",
    "X_train.head()\n",
    "X_test_All = pre_process(X_test,removeStopWords)\n",
    "X_test_All = pre_process(X_test_stopWords,lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fcdced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [07:26<00:00,  7.84s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:38<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1162, Val loss: 1.1009, Val accy: 32.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [07:00<00:00,  7.38s/it, loss=1.05]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.0519, Val loss: 1.0521, Val accy: 47.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:20<00:00,  7.73s/it, loss=0.826]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.8259, Val loss: 1.0826, Val accy: 49.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:50<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.44      0.85      0.58       344\n",
      "           B       0.45      0.20      0.28       327\n",
      "           C       0.42      0.25      0.31       326\n",
      "\n",
      "    accuracy                           0.44       997\n",
      "   macro avg       0.44      0.43      0.39       997\n",
      "weighted avg       0.44      0.44      0.39       997\n",
      "\n",
      "f1micro = 0.441 and f1macro = 0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:57<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.49      0.67      0.56       344\n",
      "           B       0.43      0.30      0.35       327\n",
      "           C       0.41      0.37      0.39       326\n",
      "\n",
      "    accuracy                           0.45       997\n",
      "   macro avg       0.44      0.45      0.43       997\n",
      "weighted avg       0.44      0.45      0.44       997\n",
      "\n",
      "f1micro = 0.449 and f1macro = 0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_All = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_All, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_All, X_test_All, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc1bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [06:57<00:00,  7.33s/it, loss=1.11]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1144, Val loss: 1.0964, Val accy: 31.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:06<00:00,  8.54s/it, loss=1.11]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:41<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.1053, Val loss: 1.0911, Val accy: 43.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:52<00:00,  9.34s/it, loss=1.07]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:41<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.0721, Val loss: 1.0850, Val accy: 38.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:52<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.36      0.76      0.49       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.38      0.32      0.34       326\n",
      "\n",
      "    accuracy                           0.37       997\n",
      "   macro avg       0.25      0.36      0.28       997\n",
      "weighted avg       0.25      0.37      0.28       997\n",
      "\n",
      "f1micro = 0.366 and f1macro = 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:59<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.41      0.55      0.47       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.34      0.57      0.43       326\n",
      "\n",
      "    accuracy                           0.38       997\n",
      "   macro avg       0.25      0.37      0.30       997\n",
      "weighted avg       0.25      0.38      0.30       997\n",
      "\n",
      "f1micro = 0.375 and f1macro = 0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train = pre_process(X_train_sample,stemmatizer)\n",
    "X_test_stem = pre_process(X_test,stemmatizer)\n",
    "\n",
    "model_stem = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_stem, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_stem, X_test_stem, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb75a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "pipe_fn = partial(ngrams, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b60a32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [07:30<00:00,  7.91s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:45<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1226, Val loss: 1.0984, Val accy: 31.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:30<00:00,  8.95s/it, loss=1.11]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:41<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.1084, Val loss: 1.0999, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|████████████████████████████████████████████████████████████| 57/57 [07:44<00:00,  8.14s/it, loss=1.1]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:42<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.1013, Val loss: 1.0942, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:27<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.36      0.43      0.39       344\n",
      "           B       0.34      0.61      0.44       327\n",
      "           C       0.00      0.00      0.00       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.23      0.35      0.28       997\n",
      "weighted avg       0.24      0.35      0.28       997\n",
      "\n",
      "f1micro = 0.349 and f1macro = 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:56<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.35      1.00      0.51       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.00      0.00      0.00       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.12      0.33      0.17       997\n",
      "weighted avg       0.12      0.35      0.18       997\n",
      "\n",
      "f1micro = 0.345 and f1macro = 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_bigram = pre_process(X_test,pipe_fn)\n",
    "\n",
    "model_bigram = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_bigram, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_bigram, X_test_bigram, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e67a82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:15<00:00,  8.70s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:38<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1211, Val loss: 1.0921, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:19<00:00,  8.77s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:39<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.1193, Val loss: 1.0970, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:18<00:00,  8.74s/it, loss=1.11]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.1110, Val loss: 1.0940, Val accy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [03:03<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.35      0.99      0.51       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.35      0.02      0.03       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.23      0.33      0.18       997\n",
      "weighted avg       0.23      0.35      0.19       997\n",
      "\n",
      "f1micro = 0.346 and f1macro = 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:58<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.35      1.00      0.51       344\n",
      "           B       0.00      0.00      0.00       327\n",
      "           C       0.00      0.00      0.00       326\n",
      "\n",
      "    accuracy                           0.35       997\n",
      "   macro avg       0.12      0.33      0.17       997\n",
      "weighted avg       0.12      0.35      0.18       997\n",
      "\n",
      "f1micro = 0.345 and f1macro = 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe_fn = partial(ngrams, n=3)\n",
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_trigram = pre_process(X_test,pipe_fn)\n",
    "\n",
    "model_trigram = model.fit(X_train, y_train)\n",
    "f1macro, f1micro = test_performance(model_trigram, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_trigram, X_test_trigram, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fae8746f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer in North America is great for skiing,  ...</td>\n",
       "      <td>Snowmen can become violent due to their isolat...</td>\n",
       "      <td>You would not want to eat a violent snowman.</td>\n",
       "      <td>The temperature in North America during the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can use detergent to dye your hair.</td>\n",
       "      <td>Detergent and bleach are both cleaning products.</td>\n",
       "      <td>Detergent and bleach cannot be used together.</td>\n",
       "      <td>Detergent isn't a hair product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passing your driving license exams requires st...</td>\n",
       "      <td>the driving license is useless for studying fo...</td>\n",
       "      <td>driving license exams needs to study for driving</td>\n",
       "      <td>You cannot drive into classes even if you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hangers bought the closet</td>\n",
       "      <td>A hanger is something you put your clothes on</td>\n",
       "      <td>Hangers are inanimate things which cannot buy ...</td>\n",
       "      <td>The hangers cannot eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee depresses people</td>\n",
       "      <td>coffee inspires people</td>\n",
       "      <td>coffee with milk is rich</td>\n",
       "      <td>coffee with cake encourages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           FalseSent   \n",
       "0  Summer in North America is great for skiing,  ...  \\\n",
       "1            You can use detergent to dye your hair.   \n",
       "2  passing your driving license exams requires st...   \n",
       "3                      The hangers bought the closet   \n",
       "4                            coffee depresses people   \n",
       "\n",
       "                                             OptionA   \n",
       "0  Snowmen can become violent due to their isolat...  \\\n",
       "1   Detergent and bleach are both cleaning products.   \n",
       "2  the driving license is useless for studying fo...   \n",
       "3      A hanger is something you put your clothes on   \n",
       "4                             coffee inspires people   \n",
       "\n",
       "                                             OptionB   \n",
       "0       You would not want to eat a violent snowman.  \\\n",
       "1      Detergent and bleach cannot be used together.   \n",
       "2   driving license exams needs to study for driving   \n",
       "3  Hangers are inanimate things which cannot buy ...   \n",
       "4                           coffee with milk is rich   \n",
       "\n",
       "                                             OptionC  \n",
       "0  The temperature in North America during the su...  \n",
       "1                    Detergent isn't a hair product.  \n",
       "2  You cannot drive into classes even if you have...  \n",
       "3                             The hangers cannot eat  \n",
       "4                        coffee with cake encourages  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72159d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert_model = 'bert-base-cased'\n",
    "\n",
    "model_cased = model.fit(X_train_sample, y_train)\n",
    "f1macro, f1micro = test_performance(model_cased, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05875579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340786f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8b8870",
   "metadata": {},
   "source": [
    "To save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "savefile = 'BERT_TaskB.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
