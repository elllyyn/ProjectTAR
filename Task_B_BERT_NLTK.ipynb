{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824f0db5",
   "metadata": {},
   "source": [
    "Source code of every test for the task A with a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He poured orange juice on his cereal.</td>\n",
       "      <td>Orange juice is usually bright orange.</td>\n",
       "      <td>Orange juice doesn't taste good on cereal.</td>\n",
       "      <td>Orange juice is sticky if you spill it on the ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He drinks apple.</td>\n",
       "      <td>Apple juice are very tasty and milk too</td>\n",
       "      <td>Apple can not be drunk</td>\n",
       "      <td>Apple cannot eat a human</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff ran 100,000 miles today</td>\n",
       "      <td>100,000 miles is way to long for one person to...</td>\n",
       "      <td>Jeff is a four letter name and 100,000 has six...</td>\n",
       "      <td>100,000 miles is longer than 100,000 km.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I sting a mosquito</td>\n",
       "      <td>A human is a mammal</td>\n",
       "      <td>A human is omnivorous</td>\n",
       "      <td>A human has not stings</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A giraffe is a person.</td>\n",
       "      <td>Giraffes can drink water from a lake.</td>\n",
       "      <td>A giraffe is not a human being.</td>\n",
       "      <td>.Giraffes usually eat leaves.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               FalseSent   \n",
       "0  He poured orange juice on his cereal.  \\\n",
       "1                       He drinks apple.   \n",
       "2           Jeff ran 100,000 miles today   \n",
       "3                     I sting a mosquito   \n",
       "4                 A giraffe is a person.   \n",
       "\n",
       "                                             OptionA   \n",
       "0             Orange juice is usually bright orange.  \\\n",
       "1            Apple juice are very tasty and milk too   \n",
       "2  100,000 miles is way to long for one person to...   \n",
       "3                                A human is a mammal   \n",
       "4              Giraffes can drink water from a lake.   \n",
       "\n",
       "                                             OptionB   \n",
       "0         Orange juice doesn't taste good on cereal.  \\\n",
       "1                             Apple can not be drunk   \n",
       "2  Jeff is a four letter name and 100,000 has six...   \n",
       "3                              A human is omnivorous   \n",
       "4                    A giraffe is not a human being.   \n",
       "\n",
       "                                             OptionC answer  \n",
       "0  Orange juice is sticky if you spill it on the ...      B  \n",
       "1                           Apple cannot eat a human      B  \n",
       "2           100,000 miles is longer than 100,000 km.      A  \n",
       "3                             A human has not stings      C  \n",
       "4                      .Giraffes usually eat leaves.      B  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files.\n",
    "# CSV task B\n",
    "def getData():\n",
    "    df_train_data = pd.read_csv(\"data/Training_Data/subtaskB_data_all.csv\")\n",
    "    df_train_answers = pd.read_csv(\"data/Training_Data/subtaskB_answers_all.csv\")\n",
    "\n",
    "    df_train = pd.merge(df_train_data,df_train_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    df_dev_data = pd.read_csv(\"data/Dev_Data/subtaskB_dev_data.csv\")\n",
    "    df_dev_answers = pd.read_csv(\"data/Dev_Data/subtaskB_gold_answers.csv\")\n",
    "\n",
    "    df_dev = pd.merge(df_dev_data,df_dev_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "\n",
    "    df_test_data = pd.read_csv(\"data/Test_Data/subtaskB_test_data.csv\")\n",
    "    df_test_answers = pd.read_csv(\"data/Test_Data/subtaskB_gold_answers.csv\")\n",
    "\n",
    "    df_test= pd.merge(df_test_data,df_test_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    return df_train, df_dev, df_test\n",
    "\n",
    "df_train_B, df_dev_B, df_test_B = getData()\n",
    "\n",
    "df_train_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ad9dd",
   "metadata": {},
   "source": [
    "Methods to pre-process the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6060bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        str+=\" \"+token.lemma_\n",
    "    return str \n",
    "\n",
    "\n",
    "def stemmatizer(text) :\n",
    "    \"\"\"\n",
    "    Receive a string in input and stem it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        str += \"\"+stemmer.stem(token.text)\n",
    "    return str\n",
    "\n",
    "def removeStopWords(text):\n",
    "    \"\"\"\n",
    "    Receives a string and remove stop words from it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if(not token.is_stop):\n",
    "            str+=\" \"+token.text\n",
    "    return str \n",
    "\n",
    "def ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Receives a text of tokens and generates n-grams.\n",
    "    \"\"\"\n",
    "    sequence=[]\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        sequence.append(token.text)\n",
    "    return list(tuple([sequence[i] for i in range(i, i+n)]) for i in range(len(sequence)-n+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9e50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dc1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synsets(text, function):\n",
    "    \"\"\"\n",
    "    Receives a text and return a list of synsets\n",
    "    \"\"\"\n",
    "    text = text.replace(\".\",\" .\")\n",
    "    sequence=text.split()\n",
    "    L = []\n",
    "    for seq in sequence:\n",
    "        L.append(tuple(function(s) for s in wn.synsets(seq)))\n",
    "    return L\n",
    "\n",
    "def getLemmasNames(synset):\n",
    "    return [str(lemma.name()) for lemma in synset.lemmas()]\n",
    "\n",
    "def getHypernyms(synset):\n",
    "    return [s.name().split(\".\")[0] for s in synset.hypernyms() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7333a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, function):\n",
    "    newdf = df[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "    newdf.loc[:,\"FalseSent\"] = df.FalseSent.apply(function)\n",
    "    newdf.loc[:,\"OptionA\"] = df.OptionA.apply(function)\n",
    "    newdf.loc[:,\"OptionB\"] = df.OptionB.apply(function)\n",
    "    newdf.loc[:,\"OptionC\"] = df.OptionC.apply(function)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9c408",
   "metadata": {},
   "source": [
    "Process of data frame, create subsample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23457d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampleData():\n",
    "    # subsample data \n",
    "    train = df_train_B.sample(n=1000, random_state=42)\n",
    "\n",
    "    X_train = train[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "    y_train = train['answer']\n",
    "\n",
    "    # use the dev set for testing  \n",
    "    return X_train, y_train\n",
    "\n",
    "X_test = df_dev_B[['FalseSent', 'OptionA', 'OptionB', 'OptionC']]\n",
    "y_test = df_dev_B['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c97f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "def test_performance(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\"), f1_score(y_pred=y_pred, y_true=y_test, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cefbe3",
   "metadata": {},
   "source": [
    "Importation of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(max_seq_length=64, train_batch_size=16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "#model.num_mlp_layers = 3\n",
    "model.max_seq_length = 64\n",
    "model.epochs = 3\n",
    "#model.learning_rate = 4e-5\n",
    "                             \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train= subsampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf29aa4",
   "metadata": {},
   "source": [
    "Fit with different preprocess type                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ad8073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>a duck walks on three legs</td>\n",
       "      <td>the duck's legs are short</td>\n",
       "      <td>a duck has only two legs</td>\n",
       "      <td>a duck has two wings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Jack's mom praised him because he broke the plate</td>\n",
       "      <td>Breaking a plate is not a good thing, people w...</td>\n",
       "      <td>Plates are easy to break, people need to be ca...</td>\n",
       "      <td>Plates can be made of ceramic or plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>People use electricity to buy things</td>\n",
       "      <td>It is impossible to buy things with electricity</td>\n",
       "      <td>Electricity is essential to live</td>\n",
       "      <td>Many appliances in home works on electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>The display is damaged, thus I can't hear anyt...</td>\n",
       "      <td>Display can also be used to create sound with ...</td>\n",
       "      <td>Display cannot be used to aid people's hearing</td>\n",
       "      <td>Display is used to display things, people will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Santa Claus is the legend of the East</td>\n",
       "      <td>Christmas is very grand in the West</td>\n",
       "      <td>The origin of Christmas is not in the East</td>\n",
       "      <td>Western countries are very respectful of Santa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FalseSent   \n",
       "6252                         a duck walks on three legs  \\\n",
       "4684  Jack's mom praised him because he broke the plate   \n",
       "1731               People use electricity to buy things   \n",
       "4742  The display is damaged, thus I can't hear anyt...   \n",
       "4521              Santa Claus is the legend of the East   \n",
       "\n",
       "                                                OptionA   \n",
       "6252                          the duck's legs are short  \\\n",
       "4684  Breaking a plate is not a good thing, people w...   \n",
       "1731    It is impossible to buy things with electricity   \n",
       "4742  Display can also be used to create sound with ...   \n",
       "4521                Christmas is very grand in the West   \n",
       "\n",
       "                                                OptionB   \n",
       "6252                           a duck has only two legs  \\\n",
       "4684  Plates are easy to break, people need to be ca...   \n",
       "1731                   Electricity is essential to live   \n",
       "4742     Display cannot be used to aid people's hearing   \n",
       "4521         The origin of Christmas is not in the East   \n",
       "\n",
       "                                                OptionC  \n",
       "6252                               a duck has two wings  \n",
       "4684           Plates can be made of ceramic or plastic  \n",
       "1731       Many appliances in home works on electricity  \n",
       "4742  Display is used to display things, people will...  \n",
       "4521  Western countries are very respectful of Santa...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b7abe5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:00<?, ?it/s]C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [06:59<00:00,  7.37s/it, loss=1.07]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.0667, Val loss: 0.9957, Val accy: 53.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:02<00:00,  7.41s/it, loss=0.855]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.8551, Val loss: 0.9771, Val accy: 55.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [06:57<00:00,  7.33s/it, loss=0.592]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:35<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.5921, Val loss: 1.0101, Val accy: 56.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:37<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.65      0.66       344\n",
      "           B       0.38      0.28      0.32       327\n",
      "           C       0.43      0.56      0.48       326\n",
      "\n",
      "    accuracy                           0.50       997\n",
      "   macro avg       0.49      0.49      0.49       997\n",
      "weighted avg       0.49      0.50      0.49       997\n",
      "\n",
      "f1micro = 0.496 and f1macro = 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_classic = model.fit(X_train_sample, y_train)\n",
    "f1macro, f1micro = test_performance(model_classic, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bbd9af",
   "metadata": {},
   "source": [
    "With lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7bfb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f0b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x00000266B0AF6E50>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:00<?, ?it/s]C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  : 100%|███████████████████████████████████████████████████████████| 57/57 [08:03<00:00,  8.48s/it, loss=1.12]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:41<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.1193, Val loss: 1.0992, Val accy: 31.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  :  74%|████████████████████████████████████████████▏               | 42/57 [06:30<02:03,  8.25s/it, loss=1.1]"
     ]
    }
   ],
   "source": [
    "pipe_fn = partial(synsets, function=getLemmasNames)\n",
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_lemma = pre_process(X_test,pipe_fn)\n",
    "\n",
    "model_lemma = model.fit(X_train, y_train)\n",
    "\n",
    "f1macro, f1micro = test_performance(model_lemma, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_lemma, X_test_lemma, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302eeb0d",
   "metadata": {},
   "source": [
    "Remove hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2233121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_fn = partial(synsets, function=getHypernyms)\n",
    "X_train = pre_process(X_train_sample,pipe_fn)\n",
    "X_test_hypernyms = pre_process(X_test,pipe_fn)\n",
    "\n",
    "model_hypernyms = model.fit(X_train, y_train)\n",
    "\n",
    "f1macro, f1micro = test_performance(model_hypernyms, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")\n",
    "f1macro, f1micro = test_performance(model_hypernyms, X_test_hypernyms, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40e94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8b8870",
   "metadata": {},
   "source": [
    "To save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "savefile = 'BERT_TaskB.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
