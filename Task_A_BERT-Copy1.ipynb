{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99912d41",
   "metadata": {},
   "source": [
    "Source code of every test for the task A with a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files.\n",
    "#CSV task A \n",
    "def getData():\n",
    "    df_train_data = pd.read_csv(\"data/Training_Data/subtaskA_data_all.csv\")\n",
    "    df_train_answers = pd.read_csv(\"data/Training_Data/subtaskA_answers_all.csv\")\n",
    "\n",
    "    df_train = pd.merge(df_train_data,df_train_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    df_dev_data = pd.read_csv(\"data/Dev_Data/subtaskA_dev_data.csv\")\n",
    "    df_dev_answers = pd.read_csv(\"data/Dev_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_dev = pd.merge(df_dev_data,df_dev_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "\n",
    "    df_test_data = pd.read_csv(\"data/Test_Data/subtaskA_test_data.csv\")\n",
    "    df_test_answers = pd.read_csv(\"data/Test_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_test= pd.merge(df_test_data,df_test_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    return df_train, df_dev, df_test\n",
    "\n",
    "df_train_A, df_dev_A, df_test_A = getData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980b04d",
   "metadata": {},
   "source": [
    "Methods to pre-process the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed3d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        str+=\" \"+token.lemma_\n",
    "    return str \n",
    "\n",
    "def stemmatizer(text) :\n",
    "    \"\"\"\n",
    "    Receive a string in input and stem it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        str += \" \"+stemmer.stem(token.text)\n",
    "    return str\n",
    "    \n",
    "def ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Receives a text and generates n-grams.\n",
    "    \"\"\"\n",
    "    sequence=[]\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc :\n",
    "        sequence.append(token.text)\n",
    "    return list(tuple([sequence[i] for i in range(i, i+n)]) for i in range(len(sequence)-n+1)) \n",
    "    \n",
    "def removeStopWords(text):\n",
    "    \"\"\"\n",
    "    Receives a string and remove stop words from it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if(not token.is_stop):\n",
    "            str+=\" \"+token.text\n",
    "    return str \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b149b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, function):\n",
    "    newdf = df[['sent0', 'sent1']]\n",
    "    newdf.loc[:,\"sent0\"] = df.sent0.apply(function)\n",
    "    newdf.loc[:,\"sent1\"] = df.sent1.apply(function)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c848f3",
   "metadata": {},
   "source": [
    "Process of data frame, create subsample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3339fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampleData():\n",
    "    # subsample data \n",
    "    train = df_train_A.sample(n=1000, random_state=42)\n",
    "    X_train = train[['sent0', 'sent1']]\n",
    "    y_train = train['answer']\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "# use the dev set for testing\n",
    "X_test = df_dev_A[['sent0', 'sent1']]\n",
    "y_test = df_dev_A['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18219886",
   "metadata": {},
   "source": [
    "Importation of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(max_seq_length=64, train_batch_size=16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "#model.num_mlp_layers = 3\n",
    "model.max_seq_length = 64\n",
    "model.epochs = 3\n",
    "#model.learning_rate = 4e-5\n",
    "                             \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train = subsampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2010901",
   "metadata": {},
   "source": [
    "Fit with different preprocess type                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29370070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>a duck walks on three legs</td>\n",
       "      <td>a duck walks on two legs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Jack's mom praised him because he broke the plate</td>\n",
       "      <td>Jack's mom condemned him because he broke the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>People use electricity to buy things</td>\n",
       "      <td>People use money to buy things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>The speaker is damaged, thus I can't hear anyt...</td>\n",
       "      <td>The display is damaged, thus I can't hear anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Santa Claus is the legend of the East</td>\n",
       "      <td>Santa Claus is the legend of the West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sent0  \\\n",
       "6252                         a duck walks on three legs   \n",
       "4684  Jack's mom praised him because he broke the plate   \n",
       "1731               People use electricity to buy things   \n",
       "4742  The speaker is damaged, thus I can't hear anyt...   \n",
       "4521              Santa Claus is the legend of the East   \n",
       "\n",
       "                                                  sent1  \n",
       "6252                           a duck walks on two legs  \n",
       "4684  Jack's mom condemned him because he broke the ...  \n",
       "1731                     People use money to buy things  \n",
       "4742  The display is damaged, thus I can't hear anyt...  \n",
       "4521              Santa Claus is the legend of the West  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b7abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_classic \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\bert_sklearn\\sklearn.py:374\u001b[0m, in \u001b[0;36mBaseBertEstimator.fit\u001b[1;34m(self, X, y, load_at_start)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(texts_a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts_b)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# finetune model!\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\bert_sklearn\\finetune.py:119\u001b[0m, in \u001b[0;36mfinetune\u001b[1;34m(model, X1, X2, y, config)\u001b[0m\n\u001b[0;32m    116\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    117\u001b[0m batch_iter \u001b[38;5;241m=\u001b[39m pbar(train_dl, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining  \u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_iter):\n\u001b[0;32m    120\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[0;32m    121\u001b[0m     loss, _ \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mbatch)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\tarproject\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_classic = model.fit(X_train_sample, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691fbcf",
   "metadata": {},
   "source": [
    "With only lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f66f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summer in North America be great for skiing ,...</td>\n",
       "      <td>summer in North America be great for swimming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you can use detergent to dye your hair .</td>\n",
       "      <td>you can use bleach to dye your hair .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pass your drive license exam require study fo...</td>\n",
       "      <td>pass your university exam require study for y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the hanger buy the closet</td>\n",
       "      <td>the closet get hanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee take sleep</td>\n",
       "      <td>coffee depress people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0  \\\n",
       "0   summer in North America be great for skiing ,...   \n",
       "1           you can use detergent to dye your hair .   \n",
       "2   pass your drive license exam require study fo...   \n",
       "3                          the hanger buy the closet   \n",
       "4                                  coffee take sleep   \n",
       "\n",
       "                                               sent1  \n",
       "0   summer in North America be great for swimming...  \n",
       "1              you can use bleach to dye your hair .  \n",
       "2   pass your university exam require study for y...  \n",
       "3                              the closet get hanger  \n",
       "4                              coffee depress people  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pre_process(X_train_sample,lemmatizer)\n",
    "X_train.head()\n",
    "\n",
    "X_train_stem = pre_process(X_train_sample, stemmatizer)\n",
    "X_train_stem.head()\n",
    "\n",
    "X_test_stem = pre_process(X_test, stemmatizer)\n",
    "X_test_stem.head()\n",
    "\n",
    "X_test_lemma = pre_process(X_test,lemmatizer)\n",
    "X_test_lemma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7d899f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:26<00:00,  7.83s/it, loss=0.733]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:55<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7330, Val loss: 0.7202, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:21<00:00,  7.74s/it, loss=0.696]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6955, Val loss: 0.7025, Val accy: 46.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:20<00:00,  7.73s/it, loss=0.664]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6645, Val loss: 0.6965, Val accy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_lemma = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfcfd4",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0203b504",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:00<?, ?it/s]D:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [08:03<00:00,  8.48s/it, loss=0.732]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:55<00:00,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7324, Val loss: 0.7294, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [08:01<00:00,  8.45s/it, loss=0.694]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [01:02<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6944, Val loss: 0.6955, Val accy: 48.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:42<00:00,  8.12s/it, loss=0.658]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:49<00:00,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6579, Val loss: 0.6786, Val accy: 49.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_stem = model.fit(X_train_stem, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a82215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer North America great skiing ,   snowsho...</td>\n",
       "      <td>Summer North America great swimming ,   boati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use detergent dye hair .</td>\n",
       "      <td>use bleach dye hair .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passing driving license exams requires studyi...</td>\n",
       "      <td>passing university exams requires studying cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hangers bought closet</td>\n",
       "      <td>closet got hangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee takes sleep</td>\n",
       "      <td>coffee depresses people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0  \\\n",
       "0   Summer North America great skiing ,   snowsho...   \n",
       "1                           use detergent dye hair .   \n",
       "2   passing driving license exams requires studyi...   \n",
       "3                              hangers bought closet   \n",
       "4                                 coffee takes sleep   \n",
       "\n",
       "                                               sent1  \n",
       "0   Summer North America great swimming ,   boati...  \n",
       "1                              use bleach dye hair .  \n",
       "2   passing university exams requires studying cl...  \n",
       "3                                 closet got hangers  \n",
       "4                            coffee depresses people  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "pipe_fn = partial(ngrams, n=2)\n",
    "X_train_bigram = pre_process(X_train_sample,removeStopWords)\n",
    "X_train_bigram.head()\n",
    "X_test_bigram = pre_process(X_test,removeStopWords)\n",
    "X_test_bigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff15d89b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:22<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.24      0.33       518\n",
      "           1       0.49      0.80      0.61       479\n",
      "\n",
      "    accuracy                           0.51       997\n",
      "   macro avg       0.52      0.52      0.47       997\n",
      "weighted avg       0.53      0.51      0.46       997\n",
      "\n",
      "f1binary = 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:24<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.01      0.03       518\n",
      "           1       0.48      0.99      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.56      0.50      0.34       997\n",
      "weighted avg       0.56      0.48      0.33       997\n",
      "\n",
      "f1binary = 0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_bigram = model.fit(X_train_bigram, y_train)\n",
    "f1binary = test_performance(model_bigram, X_test_bigram, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")\n",
    "f1binary = test_performance(model_bigram, X_test, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d1a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer North America great skiing ,   snowsho...</td>\n",
       "      <td>Summer North America great swimming ,   boati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use detergent dye hair .</td>\n",
       "      <td>use bleach dye hair .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passing driving license exams requires studyi...</td>\n",
       "      <td>passing university exams requires studying cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hangers bought closet</td>\n",
       "      <td>closet got hangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee takes sleep</td>\n",
       "      <td>coffee depresses people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0  \\\n",
       "0   Summer North America great skiing ,   snowsho...   \n",
       "1                           use detergent dye hair .   \n",
       "2   passing driving license exams requires studyi...   \n",
       "3                              hangers bought closet   \n",
       "4                                 coffee takes sleep   \n",
       "\n",
       "                                               sent1  \n",
       "0   Summer North America great swimming ,   boati...  \n",
       "1                              use bleach dye hair .  \n",
       "2   passing university exams requires studying cl...  \n",
       "3                                 closet got hangers  \n",
       "4                            coffee depresses people  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trigram = pre_process(X_train_sample,removeStopWords)\n",
    "X_train_trigram.head()\n",
    "X_test_trigram = pre_process(X_test,removeStopWords)\n",
    "X_test_trigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6376930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:39<00:00,  8.05s/it, loss=0.731]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:52<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7309, Val loss: 0.7355, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:16<00:00,  7.65s/it, loss=0.698]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6975, Val loss: 0.7010, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:21<00:00,  7.74s/it, loss=0.675]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:31<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6753, Val loss: 0.6932, Val accy: 54.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:33<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.24      0.33       518\n",
      "           1       0.49      0.80      0.61       479\n",
      "\n",
      "    accuracy                           0.51       997\n",
      "   macro avg       0.52      0.52      0.47       997\n",
      "weighted avg       0.53      0.51      0.46       997\n",
      "\n",
      "f1binary = 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:36<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.01      0.03       518\n",
      "           1       0.48      0.99      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.56      0.50      0.34       997\n",
      "weighted avg       0.56      0.48      0.33       997\n",
      "\n",
      "f1binary = 0.648\n"
     ]
    }
   ],
   "source": [
    "model_trigram = model.fit(X_train_trigram, y_train)\n",
    "f1binary = test_performance(model_trigram, X_test_trigram, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")\n",
    "f1binary = test_performance(model_trigram, X_test, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66c07bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer North America great skiing ,   snowsho...</td>\n",
       "      <td>Summer North America great swimming ,   boati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use detergent dye hair .</td>\n",
       "      <td>use bleach dye hair .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passing driving license exams requires studyi...</td>\n",
       "      <td>passing university exams requires studying cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hangers bought closet</td>\n",
       "      <td>closet got hangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee takes sleep</td>\n",
       "      <td>coffee depresses people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0  \\\n",
       "0   Summer North America great skiing ,   snowsho...   \n",
       "1                           use detergent dye hair .   \n",
       "2   passing driving license exams requires studyi...   \n",
       "3                              hangers bought closet   \n",
       "4                                 coffee takes sleep   \n",
       "\n",
       "                                               sent1  \n",
       "0   Summer North America great swimming ,   boati...  \n",
       "1                              use bleach dye hair .  \n",
       "2   passing university exams requires studying cl...  \n",
       "3                                 closet got hangers  \n",
       "4                            coffee depresses people  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pre_process(X_train_sample,removeStopWords)\n",
    "X_train.head()\n",
    "X_train_stop_stem = pre_process(X_train, stemmatizer)\n",
    "X_train_stop_stem.head()\n",
    "\n",
    "X_test_stopWord = pre_process(X_test,removeStopWords)\n",
    "X_test_stopWord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74815d59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:07<00:00,  7.50s/it, loss=0.731]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:31<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7309, Val loss: 0.7355, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:16<00:00,  7.67s/it, loss=0.698]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6975, Val loss: 0.7010, Val accy: 45.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:11<00:00,  7.58s/it, loss=0.675]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6753, Val loss: 0.6932, Val accy: 54.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_stopWords = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccac1c6",
   "metadata": {},
   "source": [
    "Score of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73491ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e67a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8746f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8bc7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(bert_model=&#x27;bert-base-cased&#x27;, max_seq_length=64,\n",
       "               train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(bert_model=&#x27;bert-base-cased&#x27;, max_seq_length=64,\n",
       "               train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(bert_model='bert-base-cased', max_seq_length=64,\n",
       "               train_batch_size=16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cased_base = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "model_cased_base.bert_model = 'bert-base-cased'\n",
    "model_cased_base.max_seq_length = 64\n",
    "model_cased_base.epochs = 3\n",
    "\n",
    "model_cased_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d216ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [08:05<00:00,  8.52s/it, loss=0.704]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:49<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.7041, Val loss: 0.6993, Val accy: 47.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:18<00:00,  7.69s/it, loss=0.701]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:31<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.7009, Val loss: 0.6997, Val accy: 47.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████████████████████████████████████████████████████| 57/57 [07:20<00:00,  7.73s/it, loss=0.699]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6988, Val loss: 0.6980, Val accy: 47.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_cased = model_cased_base.fit(X_train_stem, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb8c3235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:34<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       518\n",
      "           1       0.48      1.00      0.65       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.24      0.50      0.32       997\n",
      "weighted avg       0.23      0.48      0.31       997\n",
      "\n",
      "f1binary = 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tarproject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1binary = test_performance(model_cased, X_test, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72159d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_classic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f1micro, f1macro \u001b[38;5;241m=\u001b[39m test_performance(\u001b[43mmodel_classic\u001b[49m, X_test, y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1micro = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1micro\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1macro = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1macro\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_classic' is not defined"
     ]
    }
   ],
   "source": [
    "f1micro, f1macro = test_performance(model_classic, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a2115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:14<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54       518\n",
      "           1       0.51      0.51      0.51       479\n",
      "\n",
      "    accuracy                           0.53       997\n",
      "   macro avg       0.53      0.53      0.53       997\n",
      "weighted avg       0.53      0.53      0.53       997\n",
      "\n",
      "f1binary = 0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1binary = test_performance(model_stem, X_test, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76c9aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:25<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.37      0.43       518\n",
      "           1       0.47      0.60      0.53       479\n",
      "\n",
      "    accuracy                           0.48       997\n",
      "   macro avg       0.49      0.49      0.48       997\n",
      "weighted avg       0.49      0.48      0.48       997\n",
      "\n",
      "f1binary = 0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1binary = test_performance(model_lemma, X_test_lemma, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00aeb2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 125/125 [02:34<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.24      0.33       518\n",
      "           1       0.49      0.80      0.61       479\n",
      "\n",
      "    accuracy                           0.51       997\n",
      "   macro avg       0.52      0.52      0.47       997\n",
      "weighted avg       0.53      0.51      0.46       997\n",
      "\n",
      "f1binary = 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1binary = test_performance(model_stopWords, X_test_stopWord, y_test)\n",
    "print(f\"f1binary = {f1binary:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c368f47",
   "metadata": {},
   "source": [
    "To save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "savefile = 'BERT_TaskA.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
