{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4ec352",
   "metadata": {},
   "source": [
    "Source code of every test for the task A with a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files.\n",
    "#CSV task A \n",
    "def getData():\n",
    "    df_train_data = pd.read_csv(\"data/Training_Data/subtaskA_data_all.csv\")\n",
    "    df_train_answers = pd.read_csv(\"data/Training_Data/subtaskA_answers_all.csv\")\n",
    "\n",
    "    df_train = pd.merge(df_train_data,df_train_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    df_dev_data = pd.read_csv(\"data/Dev_Data/subtaskA_dev_data.csv\")\n",
    "    df_dev_answers = pd.read_csv(\"data/Dev_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_dev = pd.merge(df_dev_data,df_dev_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "\n",
    "    df_test_data = pd.read_csv(\"data/Test_Data/subtaskA_test_data.csv\")\n",
    "    df_test_answers = pd.read_csv(\"data/Test_Data/subtaskA_gold_answers.csv\")\n",
    "\n",
    "    df_test= pd.merge(df_test_data,df_test_answers,on='id', how='left').drop(['id'], axis=1)\n",
    "    \n",
    "    return df_train, df_dev, df_test\n",
    "\n",
    "df_train_A, df_dev_A, df_test_A = getData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b8218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4439dad",
   "metadata": {},
   "source": [
    "Methods to pre-process the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6587edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        str+=\" \"+token.lemma_\n",
    "    return str \n",
    "\n",
    "def removeStopWords(text):\n",
    "    \"\"\"\n",
    "    Receives a string and remove stop words from it.\n",
    "    \"\"\"\n",
    "    str = \"\"\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if(not token.is_stop):\n",
    "            str+=\" \"+token.text\n",
    "    return str \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63fc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, function):\n",
    "    newdf = df[['sent0', 'sent1']]\n",
    "    newdf.loc[:,\"sent0\"] = df.sent0.apply(function)\n",
    "    newdf.loc[:,\"sent1\"] = df.sent1.apply(function)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8bc6a8",
   "metadata": {},
   "source": [
    "Process of data frame, create subsample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95087a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampleData():\n",
    "    # subsample data \n",
    "    train = df_train_A.sample(n=1000, random_state=42)\n",
    "    X_train = train[['sent0', 'sent1']]\n",
    "    y_train = train['answer']\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "# use the dev set for testing\n",
    "X_test = df_dev_A[['sent0', 'sent1']]\n",
    "y_test = df_dev_A['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c987125",
   "metadata": {},
   "source": [
    "Importation of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8f2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BertClassifier</label><div class=\"sk-toggleable__content\"><pre>BertClassifier(max_seq_length=64, train_batch_size=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BertClassifier(max_seq_length=64, train_batch_size=16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64, train_batch_size=16)\n",
    "#model.num_mlp_layers = 3\n",
    "model.max_seq_length = 64\n",
    "model.epochs = 3\n",
    "#model.learning_rate = 4e-5\n",
    "                             \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8393939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6ac758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train_sample = subsampleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c0277",
   "metadata": {},
   "source": [
    "Fit with different preprocess type                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c309cbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>a duck walks on three legs</td>\n",
       "      <td>a duck walks on two legs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Jack's mom praised him because he broke the plate</td>\n",
       "      <td>Jack's mom condemned him because he broke the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>People use electricity to buy things</td>\n",
       "      <td>People use money to buy things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>The speaker is damaged, thus I can't hear anyt...</td>\n",
       "      <td>The display is damaged, thus I can't hear anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Santa Claus is the legend of the East</td>\n",
       "      <td>Santa Claus is the legend of the West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sent0   \n",
       "6252                         a duck walks on three legs  \\\n",
       "4684  Jack's mom praised him because he broke the plate   \n",
       "1731               People use electricity to buy things   \n",
       "4742  The speaker is damaged, thus I can't hear anyt...   \n",
       "4521              Santa Claus is the legend of the East   \n",
       "\n",
       "                                                  sent1  \n",
       "6252                           a duck walks on two legs  \n",
       "4684  Jack's mom condemned him because he broke the ...  \n",
       "1731                     People use money to buy things  \n",
       "4742  The display is damaged, thus I can't hear anyt...  \n",
       "4521              Santa Claus is the legend of the West  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   0%|                                                                               | 0/57 [00:00<?, ?it/s]C:\\Users\\ellyn_vdxio7o\\miniconda3\\envs\\tarProject\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  :  32%|██████████████████▎                                       | 18/57 [02:48<04:45,  7.33s/it, loss=0.798]"
     ]
    }
   ],
   "source": [
    "model_classic = model.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7a340",
   "metadata": {},
   "source": [
    "With only lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38738881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_process(X_train_sample,lemmatizer)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lemma = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8a317",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_process(X_train_sample,removeStopWords)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stopWords = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ba0fe",
   "metadata": {},
   "source": [
    "Score of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4444158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\"), f1_score(y_pred=y_pred, y_true=y_test, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8746f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72159d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1micro, f1macro = test_performance(model_classic, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5376424",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1micro, f1macro = test_performance(model_lemma, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8793898",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1micro, f1macro = test_performance(model_stopWords, X_test, y_test)\n",
    "print(f\"f1micro = {f1micro:.3f} and \"f\"f1macro = {f1macro:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c543cb",
   "metadata": {},
   "source": [
    "To save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "savefile = 'BERT_TaskA.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe21d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
